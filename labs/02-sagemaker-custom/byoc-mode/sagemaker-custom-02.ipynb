{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo um container Tensorflow para o Amazon SageMaker\n",
    "\n",
    "With Amazon SageMaker, you can package your own algorithms that can then be trained and deployed in the SageMaker environment. This notebook guides you through an example using TensorFlow that shows you how to build a Docker container for SageMaker and use it for training and inference.\n",
    "\n",
    "By packaging an algorithm in a container, you can bring almost any code to the Amazon SageMaker environment, regardless of programming language, environment, framework, or dependencies. \n",
    "\n",
    "Dataset: [CIFAR-10]: http://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Empacotando e carregando seu algoritmo para uso com o Amazon SageMaker\n",
    "\n",
    "### Overview de Docker\n",
    "\n",
    "O Docker fornece uma maneira simples de empacotar código que é totalmente autocontida. Depois de obter uma imagem, você pode usar o Docker para executar um _container_ com base nessa imagem. Executar um container é como executar um programa na máquina, exceto que o container cria um ambiente totalmente independente para o programa ser executado. Os containers são isolados uns dos outros e do ambiente host, portanto, a forma como o programa é configurado é a maneira como ele é executado, não importa onde você o execute.\n",
    "\n",
    "Alguns links interessantes:\n",
    "\n",
    "* [Docker home page](http://www.docker.com)\n",
    "* [Getting started with Docker](https://docs.docker.com/get-started/)\n",
    "* [Dockerfile reference](https://docs.docker.com/engine/reference/builder/)\n",
    "* [`docker run` reference](https://docs.docker.com/engine/reference/run/)\n",
    "\n",
    "[Amazon ECS]: https://aws.amazon.com/ecs/\n",
    "\n",
    "### Como o Amazon SageMaker executa os containers Docker\n",
    "\n",
    "O SageMaker trabalha com dois tipos de container `train` ou `serve`, mas também é possível usar a mesma imagem para as duas coisas.\n",
    "\n",
    "* Nesse exemplo, não definimos um `ENTRYPOINT` no Dockerfile, então, por padrão o Docker irá executar o comando [`train` no momento de treinamento](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html) e [`serve` no momento de inferência](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html). Nesse exemplo, definimos como scripts em Python, mas poderia ser qualquer programa.\n",
    "* Se você especificar um `ENTRYPOINT` no Dockerfile, o programa irá ser executado no startup e terá que receber os argumentos de `train` ou `serve`.\n",
    "* Se você está construindo containers diferentes para treino e inferência. No seu `ENTRYPOINT` no Dockerfile você pode ignorar o argumento não usado ou verificar.\n",
    "\n",
    "#### Executando o container durante o treinamento\n",
    "\n",
    "Tudo inicia no script `train`e a estrutura esperado no SageMaker é:\n",
    "\n",
    "    /opt/ml\n",
    "    |-- input\n",
    "    |   |-- config\n",
    "    |   |   |-- hyperparameters.json\n",
    "    |   |   `-- resourceConfig.json\n",
    "    |   `-- data\n",
    "    |       `-- <channel_name>\n",
    "    |           `-- <input data>\n",
    "    |-- model\n",
    "    |   `-- <model files>\n",
    "    `-- output\n",
    "        `-- failure\n",
    "\n",
    "##### Entrada\n",
    "\n",
    "* `/opt/ml/input/config` contém informações para controlar como seu programa é executado. `hyperparameters.json` é um dicionário formatado em JSON de nomes de hiperparâmetros para valores. Esses valores são sempre strings, portanto, pode ser necessário convertê-los. `resourceConfig.json` é um arquivo formatado em JSON que descreve o layout de rede usado para treinamento distribuído.\n",
    "* `/opt/ml/input/data/<channel_name>/` contém os dados de entrada para aquele canal. Os canais são criados com base na chamada para CreateTrainingJob, mas geralmente é importante que os canais correspondam às expectativas do algoritmo. Os arquivos de cada canal são copiados do S3 para este diretório, preservando a estrutura em árvore indicada pela estrutura de chaves do S3.\n",
    "* `/opt/ml/input/data/<channel_name>_<epoch_number>` é um canal para uma determinada epoch. As epochs começam do zero e aumentam um a cada vez que você as lê. Não há limite para o número de epochs que você pode executar, mas você deve fechar cada canal antes de ler a próxima epoch.\n",
    "\n",
    "##### Saída\n",
    "\n",
    "* `/opt/ml/model/` é onde o modelo gerado irá ser armazenado. Pode estar em qualquer formato e dividido em diferentes arquivos. O SageMaker irá empacotar o diretório e comprimir em um arquivo tar. Por fim, irá armazenar no bucket S3 especificado.\n",
    "* `/opt/ml/output` diretório de escrita temporária para por exemplo escrever logs de `failure`.\n",
    "\n",
    "#### Executando o container para inferência\n",
    "\n",
    "Amazon SageMaker usa dois resources esperando receber as requisições:\n",
    "\n",
    "* `/ping` recebe um `GET` para efetuar o healthcheck\n",
    "* `/invocations` recebe a chamada `POST` para inferências. O formato da requisição depende de cada algoritmo\n",
    "\n",
    "Os arquivos seguem a mesma estrutura que o treinamento.\n",
    "\n",
    "    /opt/ml\n",
    "    `-- model\n",
    "        `-- <model files>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As partes para criação do container\n",
    "\n",
    "A pasta `container` possui todos os componentes para a criação de um container:\n",
    "\n",
    "    .\n",
    "    |-- Dockerfile\n",
    "    |-- build_and_push.sh\n",
    "    `-- cifar10\n",
    "        |-- cifar10.py\n",
    "        |-- resnet_model.py\n",
    "        |-- nginx.conf\n",
    "        |-- serve\n",
    "        `-- train\n",
    "\n",
    "Let's discuss each of these in turn:\n",
    "\n",
    "* __`Dockerfile`__ descrição da criação da imagem Docker\n",
    "* __`build_and_push.sh`__ script para auxiliar no build e registro\n",
    "* __`cifar10`__ arquivos que estarão no container\n",
    "\n",
    "Os arquivos na pasta cifar10:\n",
    "\n",
    "* __`cifar10.py`__ script com implementação do algoritmo\n",
    "* __`resnet_model.py`__ Resnet model\n",
    "* __`nginx.conf`__ configuração do nginx\n",
    "* __`serve`__ Primeiro programa executado para inferência. Somente lança o nginx e carrega o modelo\n",
    "* __`train`__ Programa invocado na chamada do treinamento. Nesse caso, invoca o script cifar10.py com os hiperparâmetros do diretório /opt/ml/input/config/hyperparameters.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efetuando o build e registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-tf-cifar10-example\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x cifar10/train\n",
    "chmod +x cifar10/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando localmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download do dataset CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python utils/generate_cifar10_tfrecords.py --data-dir=/tmp/cifar-10-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There should be three tfrecords. (eval, train, validation)\n",
    "! ls /tmp/cifar-10-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Python SDK para teste local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit, Deploy, Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets set up our SageMaker notebook instance for local mode.\n",
    "!/bin/bash ./utils/setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'train-steps': 100}\n",
    "\n",
    "instance_type = 'local'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type=instance_type,\n",
    "                      image_name='sagemaker-tf-cifar10-example:latest',\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit('file:///tmp/cifar-10-data')\n",
    "\n",
    "predictor = estimator.deploy(1, instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predições com o SDK em Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "\n",
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "\n",
    "image = cv2.imread(\"data/cat.png\", 1)\n",
    "\n",
    "# resize, as our model is expecting images in 32x32.\n",
    "image = cv2.resize(image, (32, 32))\n",
    "\n",
    "data = {'instances': numpy.asarray(image).astype(float).tolist()}\n",
    "\n",
    "# The request and response format is JSON for TensorFlow Serving.\n",
    "# For more information: https://www.tensorflow.org/serving/api_rest#predict_api\n",
    "predictor.accept = 'application/json'\n",
    "predictor.content_type = 'application/json'\n",
    "\n",
    "predictor.serializer = json_serializer\n",
    "predictor.deserializer = json_deserializer\n",
    "\n",
    "# For more information on the predictor class.\n",
    "# https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/predictor.py\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Implantando no SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando o ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'DEMO-tensorflow-cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = '/tmp/cifar-10-data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando no SageMaker\n",
    "\n",
    "Agora vamos definir nossa imagem no ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "region = my_session.region_name\n",
    "\n",
    "algorithm_name = 'sagemaker-tf-cifar10-example'\n",
    "\n",
    "ecr_image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)\n",
    "\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'train-steps': 100}\n",
    "\n",
    "instance_type = 'ml.m4.xlarge'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type=instance_type,\n",
    "                      image_name=ecr_image,\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit(data_location)\n",
    "\n",
    "predictor = estimator.deploy(1, instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"data/cat.png\", 1)\n",
    "\n",
    "# resize, as our model is expecting images in 32x32.\n",
    "image = cv2.resize(image, (32, 32))\n",
    "\n",
    "data = {'instances': numpy.asarray(image).astype(float).tolist()}\n",
    "\n",
    "predictor.accept = 'application/json'\n",
    "predictor.content_type = 'application/json'\n",
    "\n",
    "predictor.serializer = json_serializer\n",
    "predictor.deserializer = json_deserializer\n",
    "\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências\n",
    "- [How Amazon SageMaker interacts with your Docker container for training](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html)\n",
    "- [How Amazon SageMaker interacts with your Docker container for inference](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html)\n",
    "- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "- [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk)\n",
    "- [Dockerfile](https://docs.docker.com/engine/reference/builder/)\n",
    "- [scikit-bring-your-own](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
