{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cars Plate Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste notebook estamos utilizando o resultado do GroundTruth para treinar nosso modelo. Na etapa de treinamento estamos efetuando um Hyperparameter Tuning e escolhemos o modelo com a melhor métrica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random, os, shutil, cv2, boto3, sagemaker\n",
    "import IPython.display as disp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "from datetime import datetime\n",
    "from time import gmtime, strftime\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import Markdown\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client('sagemaker')\n",
    "s3_client = boto3.client('s3')\n",
    "s3 = boto3.resource('s3')\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "bucket_manifest = '' # bucket com o manifesto de rotulação\n",
    "bucket_data = '' # bucket com as imagens\n",
    "bucket_model = '' # bucket com os modelos\n",
    "prefix_input = '' # prefix para os dados de treinamento\n",
    "prefix_test = '' # prefix para os dados de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega imagem no notebook\n",
    "def load_image(filename):\n",
    "    with open(filename, 'rb') as imageFile:\n",
    "      f = imageFile.read()\n",
    "      return bytearray(f)\n",
    "\n",
    "# desenhando a bounding box na imagem\n",
    "def visualize_detection(img_file, dets, classes=[], thresh=0.6):\n",
    "        img = mpimg.imread(img_file)\n",
    "        plt.imshow(img)\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        colors = dict()\n",
    "        for det in dets:\n",
    "            (klass, score, x0, y0, x1, y1) = det\n",
    "            if score < thresh:\n",
    "                continue\n",
    "            cls_id = int(klass)\n",
    "            print(score)\n",
    "            if cls_id not in colors:\n",
    "                colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "            xmin = int(x0 * width)\n",
    "            ymin = int(y0 * height)\n",
    "            xmax = int(x1 * width)\n",
    "            ymax = int(y1 * height)\n",
    "            rect = plt.Rectangle((xmin, ymin), xmax - xmin,\n",
    "                                 ymax - ymin, fill=False,\n",
    "                                 edgecolor=colors[cls_id],\n",
    "                                 linewidth=3.5)\n",
    "            plt.gca().add_patch(rect)\n",
    "        plt.show()\n",
    "\n",
    "# leitura do manifesto de rotulação do GroundTruth\n",
    "def read_manifest_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        output = [json.loads(line.strip()) for line in f.readlines()]\n",
    "        return output\n",
    "\n",
    "# limpeza dos dados não rotulados no manifesto\n",
    "def delete_manifest_unlabeled(output_manifest_lines, sourceref):\n",
    "    clean_manifest = []\n",
    "    for manifest_line in output_manifest_lines:\n",
    "        if sourceref in manifest_line:\n",
    "            clean_manifest.append(manifest_line)\n",
    "    return clean_manifest\n",
    "    \n",
    "# split em treinamento e validação a partir do manifesto\n",
    "def train_validation_split(labels, split_factor=0.9):\n",
    "    np.random.shuffle(labels)\n",
    "\n",
    "    dataset_size = len(labels)\n",
    "    train_test_split_index = round(dataset_size*split_factor)\n",
    "\n",
    "    train_data = labels[:train_test_split_index]\n",
    "    validation_data = labels[train_test_split_index:]\n",
    "    return train_data, validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecção de placas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando imagem com o algoritmo built-in object-detection\n",
    "training_image = get_image_uri(sess.boto_region_name, 'object-detection', repo_version='latest')\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efetuando o download do arquivos de manifesto do GroundTruth\n",
    "s3.Bucket(bucket_manifest).download_file('br-cars-plate/manifests/output/output.manifest', 'output-br-cars-plate.manifest')\n",
    "output_manifest_lines = read_manifest_file('./output-br-cars-plate.manifest')\n",
    "print(f\"loaded {len(output_manifest_lines)} lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminando dados sem rótulo\n",
    "clean_manifest = delete_manifest_unlabeled(output_manifest_lines, 'br-cars-plate')\n",
    "print(f'labeled data: {len(clean_manifest)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separação 70-30 entre dados de treino e dados de validação\n",
    "train_data, validation_data = train_validation_split(np.array(clean_manifest), split_factor=0.7)\n",
    "print(f\"training data size:{train_data.shape[0]}\")\n",
    "print(f\"validation data size:{validation_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando arquivos de treino e validação\n",
    "with open('train-br-cars-plate.manifest', 'w') as f:\n",
    "    for line in train_data:\n",
    "        f.write(json.dumps(line))\n",
    "        f.write('\\n')\n",
    "    \n",
    "with open('validation-br-cars-plate.manifest', 'w') as f:\n",
    "    for line in validation_data:\n",
    "        f.write(json.dumps(line))\n",
    "        f.write('\\n')\n",
    "        \n",
    "!wc -l train-br-cars-plate.manifest\n",
    "!wc -l validation-br-cars-plate.manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efetuando upload do manifesto de treino e validação\n",
    "s3_client.upload_file('train-br-cars-plate.manifest', bucket_manifest, 'br-cars-plate/manifests/train.manifest')\n",
    "s3_client.upload_file('validation-br-cars-plate.manifest', bucket_manifest, 'br-cars-plate/manifests/validation.manifest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição dos datasets para treinamento\n",
    "s3_train_data_path = f's3://{bucket_manifest}/br-cars-plate/manifests/train.manifest'\n",
    "s3_validation_data_path = f's3://{bucket_manifest}/br-cars-plate/manifests/validation.manifest'\n",
    "print(s3_train_data_path)\n",
    "print(s3_validation_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criação do Estimator\n",
    "s3_output_location = f's3://{bucket_model}/br-cars-plate'\n",
    "\n",
    "od_model = sagemaker.estimator.Estimator(training_image, # imagem do algoritmo\n",
    "                                         role, # role para treinamento\n",
    "                                         train_instance_count=1,\n",
    "                                         train_instance_type='ml.p3.8xlarge',\n",
    "                                         train_volume_size = 1000, # tamanho do volume das instâncias de treinamento\n",
    "                                         train_max_run = 360000, # tempo máximo em segundos para o treinamento\n",
    "                                         input_mode = 'Pipe', # modo dos dados de entrada\n",
    "                                         output_path=s3_output_location, # local de armazenamento do modelo\n",
    "                                         sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo os hiperparâmetros do algoritmo\n",
    "od_model.set_hyperparameters(base_network='resnet-50', # arquitetura de base da rede neural\n",
    "                             num_classes=1, # número de classes\n",
    "                             epochs=1000, # número de vezes que o modelo passa pelos dados de treino\n",
    "                             image_shape=640, # tamanho das imagens de treinamento\n",
    "                             label_width=600,\n",
    "                             num_training_samples=872) # quantidade de dados para treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo os dados de entrada e validação\n",
    "train_data = sagemaker.session.s3_input(s3_data=s3_train_data_path, \n",
    "                                        distribution='FullyReplicated', \n",
    "                                        content_type='application/x-recordio', \n",
    "                                        s3_data_type='AugmentedManifestFile',\n",
    "                                        record_wrapping=\"RecordIO\",\n",
    "                                        attribute_names=['source-ref', 'br-cars-plate'])\n",
    "\n",
    "validation_data = sagemaker.session.s3_input(s3_data=s3_validation_data_path, \n",
    "                                        distribution='FullyReplicated', \n",
    "                                        content_type='application/x-recordio', \n",
    "                                        s3_data_type='AugmentedManifestFile', \n",
    "                                        record_wrapping=\"RecordIO\",\n",
    "                                        attribute_names=['source-ref', 'br-cars-plate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning de hiperparâmetros com treinamento em paralelo\n",
    "hyperparameter_ranges = {'learning_rate': ContinuousParameter(0.00001, 0.5),\n",
    "                         'momentum': ContinuousParameter(0.0, 0.999),\n",
    "                         'weight_decay': ContinuousParameter(0.0, 0.999),\n",
    "                         'mini_batch_size': IntegerParameter(8, 64),\n",
    "                         'optimizer': CategoricalParameter(['sgd', 'adam', 'rmsprop', 'adadelta'])}\n",
    "\n",
    "objective_metric_name = 'validation:mAP'\n",
    "\n",
    "tuner = HyperparameterTuner(od_model, \n",
    "                            objective_metric_name, \n",
    "                            hyperparameter_ranges,\n",
    "                            objective_type='Maximize', \n",
    "                            max_jobs=20, \n",
    "                            max_parallel_jobs=2,\n",
    "                            early_stopping_type='Auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# início do treinamento\n",
    "tuning_job_name = f'br-cars-plate-{strftime(\"%d-%H-%M-%S\", gmtime())}'\n",
    "tuner.fit({'train': train_data, 'validation': validation_data}, job_name=tuning_job_name)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 modelos\n",
    "tuner_metrics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "tuner_metrics.dataframe().sort_values(['FinalObjectiveValue'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status do treinamento e tempo\n",
    "df = tuner_metrics.dataframe()\n",
    "total_time = df['TrainingElapsedTimeSeconds'].sum() / 3600\n",
    "print(f'The total training time with early stopping is {total_time} hours')\n",
    "df['TrainingJobStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinamentos que pararam\n",
    "df[df.TrainingJobStatus == 'Stopped']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_metrics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "tuner_metrics.dataframe().sort_values(['FinalObjectiveValue'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tuner_metrics.dataframe()\n",
    "total_time = df['TrainingElapsedTimeSeconds'].sum() / 3600\n",
    "print(f'The total training time with early stopping is {total_time} hours')\n",
    "df['TrainingJobStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.TrainingJobStatus == 'Stopped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy do modelo de detecção de placas com o objeto Estimator\n",
    "od_identifier = tuner.deploy(initial_instance_count = 1,\n",
    "                          instance_type = 'ml.c5.large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efetuando a Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Bucket(bucket_data).download_file('202006/test.png', 'test.png')\n",
    "disp.Image('test.png', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = load_image('test.png')\n",
    "results = od_identifier.predict(test_image)\n",
    "detections = json.loads(results)\n",
    "print(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_detection('test.png', detections['prediction'], [], 0.70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
